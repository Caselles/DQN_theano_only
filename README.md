# Double-DQN_theano_only

Author : Hugo Caselles-Dupr√© & Geoffrey Chinot

Disclaimer : several syntax errors can exist in the code. Use it wisely.

---------------------------------------
Project for ENSAE's ELTDM course : implementation of Deep Q-Network using only Theano. 
---------------------------------------

In this directory you can find a Python code with the implementation of Double DQN using only Theano. The class Experience Replay allows you train the Double DQN agent on any OpenAI Gym environment.

An example, CartPole-v0, is provided. The neural network is build with Theano, and the code is compatible with the use of GPU via CUDA.

------------------------------------------

If you have any questions : casellesdupre.hugo@gmail.com.
